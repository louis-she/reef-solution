{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成 COCO 数据集\n",
    "\n",
    "按照流程 https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data#11-create-datasetyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root path of reef dataset\n",
    "reef_dataset_root = \"/home/featurize/data\"\n",
    "\n",
    "full_df = pd.read_csv(f\"{reef_dataset_root}/train.csv\")\n",
    "\n",
    "# folowing will generate dataset for full dataset training, if you want to do experiment\n",
    "# you should change the train_df and val_df to the correct part of the data.\n",
    "# we suggest that using video_id to split the dataset for experiments.\n",
    "dest_dir = \"/home/featurize/full\"\n",
    "train_df = full_df.loc[(full_df.annotations != '[]')]\n",
    "val_df = full_df.loc[(full_df.video_id == 0) & (full_df.annotations != '[]')]\n",
    "test_df = val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2776 6708\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(dest_dir).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 创建 dataset.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = Path(f\"{dest_dir}/dataset.yaml\").write_text(f\"\"\"path: {dest_dir}\n",
    "train: images/train2017\n",
    "val: images/val2017\n",
    "test: images/test2017\n",
    "\n",
    "nc: 1\n",
    "names: ['patric']\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 复制图片文件到指定目录，同时创建对应的标签文件\n",
    "\n",
    "将图片复制到 dataset.yaml 中的 train val test 目录下。并且，在 images 同级目录创建一个 labels 目录，然后 labels 目录中为每个 image 文件创建一个对应的 txt 文件，txt 文件格式为：\n",
    "\n",
    "* 每行一个 object（一个框）\n",
    "* 每行格式为 `class x_center y_center width height`\n",
    "* 坐标全部 normalize 为 0 ~ 1 之间的数（除以高宽）\n",
    "* 类别从 0 开始\n",
    "\n",
    "如果一个图片没有标签，则不需要创建 txt 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b101c6fe2ba54b0db24e490ae1fbd768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2776 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6280ae92a6c04a6d95a8f5ac2239deda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc26ec81c874698a376f267d03433e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_txt_file(path: Path, item):\n",
    "    \"\"\"根据 item 生成 txt 文件，并写入在对应的 path\n",
    "    \"\"\"\n",
    "    if item.annotations == \"[]\":\n",
    "        return\n",
    "    anno_str = []\n",
    "    for anno in eval(item.annotations):\n",
    "        x, y, w, h = anno['x'] / 1280, anno['y'] / 720, anno['width'] / 1280, anno['height'] / 720\n",
    "\n",
    "        # 有部分框超出边界\n",
    "        h = min((1 - y), h)\n",
    "        w = min((1 - x), w)\n",
    "\n",
    "        xc = x + w / 2\n",
    "        yc = y + h / 2\n",
    "        anno_str.append(f\"0 {xc} {yc} {w} {h}\")\n",
    "    path.write_text(\"\\n\".join(anno_str))\n",
    "\n",
    "\n",
    "for mode in [\"train\", \"val\", \"test\"]:\n",
    "    image_folder = Path(dest_dir) / \"images\" / f\"{mode}2017\"\n",
    "    image_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    label_folder = Path(dest_dir) / \"labels\" / f\"{mode}2017\"\n",
    "    label_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = locals().get(f\"{mode}_df\")\n",
    "\n",
    "    for _, item in tqdm(df.iterrows(), total=len(df)):\n",
    "        file_name = f\"{item.video_id}_{item.video_frame}\"\n",
    "        shutil.copy(f\"{reef_dataset_root}/train_images/video_{item.video_id}/{item.video_frame}.jpg\", image_folder / f\"{file_name}.jpg\")\n",
    "        create_txt_file(Path(label_folder) / f\"{file_name}.txt\", item)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b114295533213be714c497b6c7c7c36862ca698da8b4418201631177dea05d47"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
